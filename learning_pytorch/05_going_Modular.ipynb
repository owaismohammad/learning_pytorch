{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94f4808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting going_modular/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/data_setup.py\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "NUM_WORKER = os.cpu_count()\n",
    "\n",
    "def create_dataloader(\n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transforms: transforms.Compose,\n",
    "    batch_size: int,\n",
    "):\n",
    "    train_data = datasets.ImageFolder(\n",
    "        root = train_dir,\n",
    "        transform = transforms,\n",
    "        ) \n",
    "    test_data = datasets.ImageFolder(\n",
    "        root = test_dir,\n",
    "        transform = transforms\n",
    "    )\n",
    "    \n",
    "    \n",
    "    class_names = train_data.classes\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        dataset= train_data,\n",
    "        batch_size= batch_size,\n",
    "        shuffle= True,\n",
    "        num_workers= NUM_WORKER,\n",
    "        pin_memory= True\n",
    "    )\n",
    "    \n",
    "    test_dataloader = DataLoader(\n",
    "        dataset=test_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKER,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c5741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/model_builder.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    def __init__(self, in_channels:int, out_shape:int, hidden_units:int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(num_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride = 1,\n",
    "                      padding=1),\n",
    "            nn.BatchNorm2d(num_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride = 2))\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*16*16,\n",
    "                      out_features=out_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.conv_block_1(X)\n",
    "        X = self.conv_block_2(X)\n",
    "        X = self.classifier(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdf2e414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/engine.py\n",
    "\n",
    "import test\n",
    "import torch.utils.data.dataloader\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_step(train_dataloader: torch.utils.data.DataLoader,\n",
    "               model: nn.Module,\n",
    "               loss_fn: nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device ,\n",
    "               \n",
    "               ):\n",
    "    \n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        model.train()\n",
    "        for X,y in train_dataloader:\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            acc = (y_pred.argmax(dim=1) == y).sum().item() / len(y)\n",
    "            train_loss += loss\n",
    "            train_acc += acc\n",
    "        train_acc /= len(train_dataloader)\n",
    "        train_loss /= len(train_dataloader)\n",
    "        return train_loss, train_acc\n",
    "    \n",
    "    \n",
    "def test_step(model:nn.Module,\n",
    "              loss_fn:nn.Module,\n",
    "              test_dataloader:torch.utils.data.DataLoader,\n",
    "              device:torch.device):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        test_loss = 0 \n",
    "        test_acc = 0\n",
    "        for X,y in test_dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            acc = (y_pred.argmax(dim=1)== y).sum().item() / len(y)\n",
    "            test_loss += loss\n",
    "            test_acc += acc\n",
    "        test_acc/= len(test_dataloader)\n",
    "        test_loss /= len(test_dataloader)\n",
    "    return test_loss, test_acc\n",
    "        \n",
    "        \n",
    "def train(model: nn.Module,\n",
    "          loss_fn: nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int,\n",
    "          device:torch.device,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader):\n",
    "    \n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\" : [],\n",
    "        \"test_loss\" : [],\n",
    "        \"test_acc\"  : []\n",
    "    }\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        train_loss, train_acc =train_step(train_dataloader=train_dataloader,\n",
    "                                            model= model,\n",
    "                                            loss_fn=loss_fn,\n",
    "                                            optimizer=optimizer,\n",
    "                                            device=device)\n",
    "        test_loss , test_acc = test_step(model= model,\n",
    "                                         loss_fn=loss_fn,\n",
    "                                         test_dataloader=test_dataloader,\n",
    "                                         device=device)\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        print(f\"EPOCH: {epoch+1}\\n Train Loss : {train_loss} , Train Accuracy : {train_acc} | Test Loss : {test_loss} , Test Acc : {test_acc}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d89e55d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing going_modular/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile going_modular/utils.py\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model(model:torch.nn.Module,\n",
    "               target_dir:str,\n",
    "               model_name: str):\n",
    "    target_dir_path = Path(target_dir)\n",
    "    \n",
    "    if target_dir_path.is_dir():\n",
    "        print(f\"{target_dir_path} already exists!!\")\n",
    "    else:\n",
    "        target_dir_path.mkdir(parents = True, exist_ok=True)\n",
    "        \n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\")\n",
    "    model_save_path = target_dir_path / model_name\n",
    "    torch.save(obj = model.state_dict(),\n",
    "               f = model_save_path)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c02ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "globalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
