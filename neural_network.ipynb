{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b2a417d",
   "metadata": {},
   "source": [
    "### In this notebook we will create an image classifier to detect playing cards\n",
    "\n",
    "we will tackle this problem in three parts\n",
    "\n",
    "1. pytorch Dataset\n",
    "2. pytorch Model\n",
    "3. Pytorch Training Loop\n",
    "\n",
    "Almost every pytorch model training pipeline meets this paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcb45bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (1.0.15)\n",
      "Requirement already satisfied: torch in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from timm) (2.7.1)\n",
      "Requirement already satisfied: torchvision in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from timm) (0.22.1)\n",
      "Requirement already satisfied: pyyaml in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from timm) (0.33.0)\n",
      "Requirement already satisfied: safetensors in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: filelock in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from huggingface_hub->timm) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from huggingface_hub->timm) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from huggingface_hub->timm) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from huggingface_hub->timm) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from huggingface_hub->timm) (1.1.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (2025.6.15)\n",
      "Requirement already satisfied: setuptools in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torch->timm) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: numpy in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torchvision->timm) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/owais/.venvs/globalenv/lib/python3.12/site-packages (from torchvision->timm) (11.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "670aa9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b3c5b",
   "metadata": {},
   "source": [
    "Setting up the dataset\n",
    "\n",
    "would you like to bake a cake without first having the ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12417861",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlayingCard(Dataset):\n",
    "    def __init__(self, data_dir, transform = None): #tells the class what todo when created\n",
    "        super().__init__()\n",
    "        self.data = ImageFolder(data_dir, transform = transform)\n",
    "        \n",
    "    def __len__(self): #dataloader needs to know no. of eg\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx): #takes idx loc and ret 1 itm\n",
    "        return self.data[idx]\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19493cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0bd08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PlayingCard(\n",
    "    data_dir='playing_cards/train',\n",
    "    transform= transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bbf8b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "image, label = dataset[100]\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b762b410",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "  Batching our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fb34dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07141d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, labels in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86b2bd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 128, 128]),\n",
       " torch.Size([32]),\n",
       " tensor([14, 49, 36, 51, 16, 42, 27, 14, 39, 21,  8, 32, 46, 46, 30, 46, 17, 26,\n",
       "         32,  5, 39, 52, 22, 15, 18, 43, 30, 38, 22,  5, 28, 37]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape, labels.shape, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611134af",
   "metadata": {},
   "source": [
    "# Making a Pytorch a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCardClassifier(nn.Module):\n",
    "    def __init__(self, num_class= 53):\n",
    "        super().__init__()\n",
    "        self.base_model = timm.create_model('efficientnet_b0', pretrained = True)\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "        enet_out_size =1280\n",
    "        self.classifier = nn.Linear(enet_out_size, num_class)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCardClassifier()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hehehe')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "globalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
